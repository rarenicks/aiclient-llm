# aiclient-llm Documentation ğŸ“š

Welcome to the documentation for `aiclient-llm`. Here you'll find everything you need to build production-ready AI applications.

## Table of Contents

### Basics
- [**Getting Started**](getting_started.md): Installation, first steps, and configuration.
- [**Feature Overview**](features.md): High-level overview of capabilities like local LLMs and streaming.
- [**Error Handling**](errors.md): Understanding and handling exceptions.

### Core Features
- [**Agents & MCP**](agents.md) ğŸ¤–: Building tool-using agents and connecting to external MCP servers.
- [**Embeddings**](embeddings.md) ğŸ”¢: Using the unified embeddings API for vector search.
- [**Memory Management**](memory.md) ğŸ§ : Managing conversation history and context.

### Production Readiness
- [**Resilience**](resilience.md) ğŸ›¡ï¸: Circuit breakers, retries, rate limiters, and fallbacks.
- [**Observability**](observability.md) ğŸ”­: Cost tracking, logging, and OpenTelemetry tracing.
- [**Middleware**](middleware.md) âš™ï¸: Understanding the middleware pipeline and creating custom interceptors.

### Development Workflow
- [**Testing**](testing.md) ğŸ§ª: Using `MockProvider` and utilities for deterministic testing.
- [**Examples**](../examples/): Runnable scripts in the main repository.
